name: Build GPUFl Client

on:
  push:
    branches: [ "main" ]
  pull_request:
    branches: [ "main" ]

jobs:
  build:
    name: Build on ${{ matrix.os }}
    runs-on: ${{ matrix.os }}
    strategy:
      matrix:
        os: [ubuntu-22.04, windows-latest]
        python-version: ["3.12", "3.13"]

    env:
      CMAKE_ARGS: >-
        -DGPUFL_ENABLE_NVIDIA=ON
        -DGPUFL_ENABLE_AMD=OFF
        -DBUILD_TESTING=OFF  

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}

      # Install CUDA Toolkit (provides CUDA_PATH)
      - name: Install CUDA Toolkit
        uses: Jimver/cuda-toolkit@v0.2.30
        id: cuda-toolkit
        with:
          cuda: '13.1.0'
          method: 'network'
          use-github-cache: false

      # Make sure CMake can find CUDA headers/libraries during the *pip build*.
      # Jimver/cuda-toolkit sets CUDA_PATH; we map it to common vars CMake respects.
      - name: Export CUDA environment for CMake
        shell: bash
        run: |
          echo "CUDA_HOME=${CUDA_PATH}" >> $GITHUB_ENV
          echo "CUDAToolkit_ROOT=${CUDA_PATH}" >> $GITHUB_ENV
          if [ "${{ runner.os }}" == "Windows" ]; then
            echo "${CUDA_PATH}/bin" >> $GITHUB_PATH
            echo "${CUDA_PATH}/extras/CUPTI/lib64" >> $GITHUB_PATH
            echo "C:/Program Files/NVIDIA Corporation/NVSMI" >> $GITHUB_PATH
          fi

      - name: Install system dependencies
        if: runner.os == 'Linux'
        run: |
          sudo apt-get update
          sudo apt-get install -y libcurl4-openssl-dev

      - name: Install python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install scikit-build-core pybind11 cmake ninja

      - name: Build and Install
        run: |
          pip install .[viz,analyzer] -v

      - name: Run C++ Unit Tests
        # Skip C++ tests on Windows as they require actual NVIDIA GPUs to run (CUDA/CUPTI initialization)
        if: runner.os != 'Windows'
        shell: bash
        run: |
          # 1. Prepare a local writable directory for CUDA stubs
          # We cannot write to the system CUDA directory (Permission denied).
          LOCAL_STUBS_DIR="${GITHUB_WORKSPACE}/local_cuda_stubs"
          mkdir -p "${LOCAL_STUBS_DIR}"

          # 2. Gather relevant library directories for the CUDA Toolkit
          STUBS_DIR="${CUDA_HOME}/targets/x86_64-linux/lib/stubs"
          LIBS_DIR="${CUDA_HOME}/targets/x86_64-linux/lib"
          
          # 3. Create versioned symlinks in the LOCAL directory
          # Many binaries expect .so.1 which is only created by the driver installer.
          for lib in libcuda libnvidia-ml libnvrtc; do
            if [ -f "${STUBS_DIR}/${lib}.so" ]; then
              # Symlink the original stub to our local dir
              ln -sf "${STUBS_DIR}/${lib}.so" "${LOCAL_STUBS_DIR}/${lib}.so"
              # Create the versioned symlink in our local dir
              ln -sf "${lib}.so" "${LOCAL_STUBS_DIR}/${lib}.so.1"
            fi
          done

          # 4. Add local stubs and toolkit libs to LD_LIBRARY_PATH
          export LD_LIBRARY_PATH="${LOCAL_STUBS_DIR}:${LIBS_DIR}:${LD_LIBRARY_PATH}"
          
          # Debug: check what libraries are found
          echo "LD_LIBRARY_PATH: $LD_LIBRARY_PATH"
          ls -l "${LOCAL_STUBS_DIR}" || true

          cmake -B build_tests -S . \
            -DGPUFL_ENABLE_NVIDIA=ON \
            -DBUILD_PYTHON=OFF \
            -DBUILD_TESTING=ON
          
          cmake --build build_tests --target gpufl_tests
          
          ctest --test-dir build_tests --output-on-failure --verbose --timeout 60

      - name: Run Python Unit Tests
        shell: bash
        run: |
          python -m pip install pytest
          export PYTHONPATH=$PYTHONPATH:$(pwd)/python
          python -m pytest tests/python

      - name: Verify Logging Pipeline
        run: |
          python -u tests/verify_pipeline.py
